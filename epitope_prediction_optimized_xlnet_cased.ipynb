{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/refine-epitope-deep-learning')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GLxgv9OSFqYi","executionInfo":{"status":"ok","timestamp":1655776345762,"user_tz":180,"elapsed":29717,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"9411ece8-c2bf-46b3-ce50-765d4c748f55"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!pip install transformers\n","!pip install optuna\n","!pip install SentencePiece"],"metadata":{"id":"Eu47NwKQudlO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Preprocess data "],"metadata":{"id":"QEpSHqtISuKr"}},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import torch\n","from transformers import TrainingArguments, Trainer\n","from transformers import BertTokenizer, BertForSequenceClassification\n","#from transformers import EarlyStoppingCallback\n","from transformers import XLNetModel, XLNetTokenizer, XLNetForSequenceClassification\n","from transformers import EarlyStoppingCallback"],"metadata":{"id":"eNWYJ8r-c_w3","executionInfo":{"status":"ok","timestamp":1655776374253,"user_tz":180,"elapsed":3017,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"],"metadata":{"id":"aj8NS4koSdbh","executionInfo":{"status":"ok","timestamp":1655776374254,"user_tz":180,"elapsed":21,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def preprocess_data(data):\n","\n","    # Preprocess data\n","    X = list(data[\"sequence\"])\n","    y = list(data[\"label\"])\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1)\n","    X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","    X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","\n","    train_dataset = Dataset(X_train_tokenized, y_train)\n","    val_dataset = Dataset(X_val_tokenized, y_val)\n","    return train_dataset, val_dataset"],"metadata":{"id":"Q3IrTXnUzpRD","executionInfo":{"status":"ok","timestamp":1655776374255,"user_tz":180,"elapsed":19,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv(\"./input/data_train.csv\")\n","\n","sequence_formatted = []\n","for seq in df_train['sequence'].values:\n","  sequence_formatted.append(\" \".join(seq))\n","\n","data = pd.DataFrame({'sequence':sequence_formatted, 'label':df_train['label'].tolist()})\n","\n","data_op = data[:int(len(data)/7)]\n","\n","\n","# Define pretrained tokenizer and model\n","batch_size=8\n","model_name = \"xlnet-base-cased\"\n","\n","tokenizer = XLNetTokenizer.from_pretrained(model_name, do_lower_case=True)\n","model = XLNetForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","\n","\n","\n","train_dataset_op, val_dataset_op = preprocess_data(data_op)\n","train_dataset, val_dataset = preprocess_data(data)\n","\n","# ----- 2. Fine-tune pretrained model -----#\n","# Define Trainer parameters\n","def compute_metrics(p):\n","    \n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred)\n","    precision = precision_score(y_true=labels, y_pred=pred)\n","    f1 = f1_score(y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","# Define Trainer\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-classification\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    \n","    #evaluation_strategy ='steps',\n","    #eval_steps = 50, # Evaluation and Save happens every 50 steps\n","    #save_total_limit = 5, # Only last 5 models are saved. Older ones are deleted.\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=5,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    optim=\"adamw_torch\"\n",")\n","\n","def model_init():\n","    return model\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=train_dataset_op,\n","    eval_dataset=val_dataset_op,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n","  #  callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",")\n","\n","\n","best_run = trainer.hyperparameter_search(n_trials=5, direction=\"maximize\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["ba356c6ec7224fb6a5caa844d1f0e0dd","5fe39121fbdc45cca9d499618e1df848","582f1fae1ea04ba7951cfe56e6a8ae38","c795b26a6ec945bf9a4dbb5121d1d62a","8943a13289734e459d934d84a89e60e7","3911d192d0234f579294f56e6c707c74","b4167b5709e94e85a31fa7954d44d883","74d794a8186b41219a95f19407a60b74","2513cf9443a54a599023e4d58c1a757a","657a0f7927ec4de48c15cfcfa09dac1d","d154a8aac8bf46acb51f6c383d6e8355","72396a6d2745431186f72c45f9c0cbe9","0cb7d7f57d894b3c96a7b00cfd3d4b9d","8401216c6779453dbf7c40508413167c","dc84d268550b445ca2be57485d075272","d8a5ab50292345cb9f38dcc733acc1b3","0d38fd9490bd4cf3a30d0498e7a8a64b","10b700e3aa0044d38d46746f4f654518","67b14fe15d044c8f8507089a536d827e","917a75a0a61e420888b4fb21bcfe4b74","37f05a8c30c94039a539c213f671d4c0","567ebadcc4f6402a874511f91d075f0c","c5338f2960a742239c389ea1cb27fddc","19566aeb5fc44834876512eb35f59e1d","d5063d7094764d49ab0db7b304dfc312","c12c278119bb48c3975bad0db3995e06","e7cf09a88641432b8fa3f3a05784270b","1ec49031dc8a4272b083ebe1849e63a0","c04680ce084648b2bade574e3cb53714","713f4f578b71461791f17fc31e8960ea","d1f4c8cd4bd5498fafa0951dd6f1b279","8b1790a8cc1246febe1b02be7e35e115","65c48d1c432f468ba766d133fb1131fc"]},"id":"61S6rdO_FPMP","executionInfo":{"status":"ok","timestamp":1655776687531,"user_tz":180,"elapsed":313293,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"04d143e6-35e9-4210-fa0b-1245e7e2d619"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ba356c6ec7224fb6a5caa844d1f0e0dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/760 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72396a6d2745431186f72c45f9c0cbe9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/445M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c5338f2960a742239c389ea1cb27fddc"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetForSequenceClassification: ['lm_loss.weight', 'lm_loss.bias']\n","- This IS expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing XLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of XLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary.summary.weight', 'logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m[I 2022-06-21 01:53:34,133]\u001b[0m A new study created in memory with name: no-name-aa37f04f-71f4-4a2c-ac2e-e908b18f21e3\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 106\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 28\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='28' max='28' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [28/28 00:35, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.402374</td>\n","      <td>0.750000</td>\n","      <td>1.000000</td>\n","      <td>0.500000</td>\n","      <td>0.666667</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.237207</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-0/checkpoint-14\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-14/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-14/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-14/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-14/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-0/checkpoint-28\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-28/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-28/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-28/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-0/checkpoint-28/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/run-0/checkpoint-28 (score: 0.923076923076923).\n","\u001b[32m[I 2022-06-21 01:54:11,069]\u001b[0m Trial 0 finished with value: 3.6968864468864466 and parameters: {'learning_rate': 2.427765586381387e-05, 'num_train_epochs': 2, 'seed': 2, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 3.6968864468864466.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 106\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 16\n","  Total train batch size (w. parallel, distributed & accumulation) = 16\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 70\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [70/70 01:35, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.238262</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.223975</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.227401</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.240175</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.223336</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-1/checkpoint-14\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-14/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-14/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-14/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-14/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-1/checkpoint-28\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-28/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-28/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-28/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-28/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-1/checkpoint-42\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-42/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-42/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-42/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-42/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-1/checkpoint-56\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-56/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-56/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-56/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-56/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-1/checkpoint-70\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-70/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-70/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-70/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-1/checkpoint-70/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/run-1/checkpoint-14 (score: 0.923076923076923).\n","\u001b[32m[I 2022-06-21 01:55:47,471]\u001b[0m Trial 1 finished with value: 3.6968864468864466 and parameters: {'learning_rate': 7.271266534024431e-06, 'num_train_epochs': 5, 'seed': 22, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 3.6968864468864466.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 106\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14/14 00:18, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.285204</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-2/checkpoint-14\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-2/checkpoint-14/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-2/checkpoint-14/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-2/checkpoint-14/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-2/checkpoint-14/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/run-2/checkpoint-14 (score: 0.923076923076923).\n","\u001b[32m[I 2022-06-21 01:56:06,979]\u001b[0m Trial 2 finished with value: 3.6968864468864466 and parameters: {'learning_rate': 1.6103970383052136e-05, 'num_train_epochs': 1, 'seed': 19, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 3.6968864468864466.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 106\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 8\n","  Total train batch size (w. parallel, distributed & accumulation) = 8\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 70\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='70' max='70' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [70/70 01:37, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.257046</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.278371</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.290361</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","      <td>0.833333</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.251457</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.249401</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-3/checkpoint-14\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-14/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-14/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-14/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-14/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-3/checkpoint-28\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-28/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-28/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-28/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-28/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-3/checkpoint-42\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-42/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-42/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-42/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-42/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-3/checkpoint-56\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-56/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-56/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-56/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-56/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-3/checkpoint-70\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-70/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-70/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-70/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-3/checkpoint-70/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/run-3/checkpoint-14 (score: 0.923076923076923).\n","\u001b[32m[I 2022-06-21 01:57:45,725]\u001b[0m Trial 3 finished with value: 3.6968864468864466 and parameters: {'learning_rate': 7.552955281899622e-06, 'num_train_epochs': 5, 'seed': 37, 'per_device_train_batch_size': 8}. Best is trial 0 with value: 3.6968864468864466.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 106\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 14\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [14/14 00:18, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.254451</td>\n","      <td>0.916667</td>\n","      <td>0.857143</td>\n","      <td>1.000000</td>\n","      <td>0.923077</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 12\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/run-4/checkpoint-14\n","Configuration saved in xlnet-base-cased-finetuned-classification/run-4/checkpoint-14/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/run-4/checkpoint-14/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/run-4/checkpoint-14/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/run-4/checkpoint-14/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/run-4/checkpoint-14 (score: 0.923076923076923).\n","\u001b[32m[I 2022-06-21 01:58:04,977]\u001b[0m Trial 4 finished with value: 3.6968864468864466 and parameters: {'learning_rate': 1.0325169188158175e-06, 'num_train_epochs': 1, 'seed': 3, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 3.6968864468864466.\u001b[0m\n"]}]},{"cell_type":"markdown","source":["## Set the model with the best parameters and run it on the full dataset"],"metadata":{"id":"CDK2oaTH4uLJ"}},{"cell_type":"code","source":["for n, v in best_run.hyperparameters.items():\n","    setattr(trainer.args, n, v)\n","\n","trainer.train_dataset=train_dataset\n","trainer.eval_dataset=val_dataset\n","\n","trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":677},"id":"neG3sjnaUHP_","outputId":"07ea6f73-e0f0-46d7-fe07-6593ece060a5","executionInfo":{"status":"ok","timestamp":1655777198140,"user_tz":180,"elapsed":178851,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 743\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 186\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='186' max='186' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [186/186 02:57, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.854726</td>\n","      <td>0.795181</td>\n","      <td>0.933333</td>\n","      <td>0.466667</td>\n","      <td>0.622222</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.312155</td>\n","      <td>0.891566</td>\n","      <td>0.862069</td>\n","      <td>0.833333</td>\n","      <td>0.847458</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 83\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='37' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26/26 03:57]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to xlnet-base-cased-finetuned-classification/checkpoint-93\n","Configuration saved in xlnet-base-cased-finetuned-classification/checkpoint-93/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/checkpoint-93/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/checkpoint-93/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/checkpoint-93/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 83\n","  Batch size = 8\n","Saving model checkpoint to xlnet-base-cased-finetuned-classification/checkpoint-186\n","Configuration saved in xlnet-base-cased-finetuned-classification/checkpoint-186/config.json\n","Model weights saved in xlnet-base-cased-finetuned-classification/checkpoint-186/pytorch_model.bin\n","tokenizer config file saved in xlnet-base-cased-finetuned-classification/checkpoint-186/tokenizer_config.json\n","Special tokens file saved in xlnet-base-cased-finetuned-classification/checkpoint-186/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from xlnet-base-cased-finetuned-classification/checkpoint-186 (score: 0.847457627118644).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=186, training_loss=0.37586675664430025, metrics={'train_runtime': 178.3775, 'train_samples_per_second': 8.331, 'train_steps_per_second': 1.043, 'total_flos': 423332095414272.0, 'train_loss': 0.37586675664430025, 'epoch': 2.0})"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["# Load trained model\n","#model_path = \"xlnet-base-cased-finetuned-classification/checkpoint-3168\"\n","#model = XLNetForSequenceClassification.from_pretrained(model_path, num_labels=2)\n","\n","\n","# Define test trainer\n","#trainer = Trainer(model)"],"metadata":{"id":"eeIRaIj-vtIX","executionInfo":{"status":"ok","timestamp":1655776864790,"user_tz":180,"elapsed":36,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# ----- 3. Predict -----#\n","# Load test data\n","#test_data = pd.read_csv(\"test.csv\")\n","test = pd.read_csv(\"./input/data_test.csv\")\n","\n","sequence_formatted = []\n","for seq in test['sequence'].values:\n","  sequence_formatted.append(\" \".join(seq))\n","\n","test_data = pd.DataFrame({'sequence':sequence_formatted, 'label':test['label'].tolist()})\n","\n","\n","X_test = list(test_data[\"sequence\"])\n","X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n","\n","# Create torch dataset\n","test_dataset = Dataset(X_test_tokenized)\n","\n","# Make prediction\n","raw_pred, _, _ = trainer.predict(test_dataset)\n","\n","# Preprocess raw predictions\n","y_pred = np.argmax(raw_pred, axis=1)"],"metadata":{"id":"Jvyc17u1IB2H","colab":{"base_uri":"https://localhost:8080/","height":87},"executionInfo":{"status":"ok","timestamp":1655776874614,"user_tz":180,"elapsed":9848,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"7626e19e-75f3-43c7-aeb8-d6c6f9bcd816"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 207\n","  Batch size = 8\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [26/26 00:09]\n","    </div>\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","\n","print(\"ROC_AUC:\", roc_auc_score(test_data['label'], y_pred))\n","\n","print(classification_report(test_data['label'], y_pred))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWPxB7pbgk_y","executionInfo":{"status":"ok","timestamp":1655776874615,"user_tz":180,"elapsed":30,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"e74cd7e3-8f75-4ae9-8b77-376e1835135b"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["ROC_AUC: 0.8515087853323147\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.91      0.88       119\n","           1       0.86      0.80      0.83        88\n","\n","    accuracy                           0.86       207\n","   macro avg       0.86      0.85      0.86       207\n","weighted avg       0.86      0.86      0.86       207\n","\n"]}]}],"metadata":{"colab":{"name":"epitope_prediction_optimized_xlnet_cased.ipynb","provenance":[],"collapsed_sections":[]},"language_info":{"name":"python"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ba356c6ec7224fb6a5caa844d1f0e0dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5fe39121fbdc45cca9d499618e1df848","IPY_MODEL_582f1fae1ea04ba7951cfe56e6a8ae38","IPY_MODEL_c795b26a6ec945bf9a4dbb5121d1d62a"],"layout":"IPY_MODEL_8943a13289734e459d934d84a89e60e7"}},"5fe39121fbdc45cca9d499618e1df848":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3911d192d0234f579294f56e6c707c74","placeholder":"​","style":"IPY_MODEL_b4167b5709e94e85a31fa7954d44d883","value":"Downloading: 100%"}},"582f1fae1ea04ba7951cfe56e6a8ae38":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_74d794a8186b41219a95f19407a60b74","max":798011,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2513cf9443a54a599023e4d58c1a757a","value":798011}},"c795b26a6ec945bf9a4dbb5121d1d62a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_657a0f7927ec4de48c15cfcfa09dac1d","placeholder":"​","style":"IPY_MODEL_d154a8aac8bf46acb51f6c383d6e8355","value":" 779k/779k [00:00&lt;00:00, 798kB/s]"}},"8943a13289734e459d934d84a89e60e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3911d192d0234f579294f56e6c707c74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b4167b5709e94e85a31fa7954d44d883":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"74d794a8186b41219a95f19407a60b74":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2513cf9443a54a599023e4d58c1a757a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"657a0f7927ec4de48c15cfcfa09dac1d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d154a8aac8bf46acb51f6c383d6e8355":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72396a6d2745431186f72c45f9c0cbe9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0cb7d7f57d894b3c96a7b00cfd3d4b9d","IPY_MODEL_8401216c6779453dbf7c40508413167c","IPY_MODEL_dc84d268550b445ca2be57485d075272"],"layout":"IPY_MODEL_d8a5ab50292345cb9f38dcc733acc1b3"}},"0cb7d7f57d894b3c96a7b00cfd3d4b9d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0d38fd9490bd4cf3a30d0498e7a8a64b","placeholder":"​","style":"IPY_MODEL_10b700e3aa0044d38d46746f4f654518","value":"Downloading: 100%"}},"8401216c6779453dbf7c40508413167c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_67b14fe15d044c8f8507089a536d827e","max":760,"min":0,"orientation":"horizontal","style":"IPY_MODEL_917a75a0a61e420888b4fb21bcfe4b74","value":760}},"dc84d268550b445ca2be57485d075272":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_37f05a8c30c94039a539c213f671d4c0","placeholder":"​","style":"IPY_MODEL_567ebadcc4f6402a874511f91d075f0c","value":" 760/760 [00:00&lt;00:00, 17.4kB/s]"}},"d8a5ab50292345cb9f38dcc733acc1b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d38fd9490bd4cf3a30d0498e7a8a64b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"10b700e3aa0044d38d46746f4f654518":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"67b14fe15d044c8f8507089a536d827e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"917a75a0a61e420888b4fb21bcfe4b74":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"37f05a8c30c94039a539c213f671d4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"567ebadcc4f6402a874511f91d075f0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c5338f2960a742239c389ea1cb27fddc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_19566aeb5fc44834876512eb35f59e1d","IPY_MODEL_d5063d7094764d49ab0db7b304dfc312","IPY_MODEL_c12c278119bb48c3975bad0db3995e06"],"layout":"IPY_MODEL_e7cf09a88641432b8fa3f3a05784270b"}},"19566aeb5fc44834876512eb35f59e1d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ec49031dc8a4272b083ebe1849e63a0","placeholder":"​","style":"IPY_MODEL_c04680ce084648b2bade574e3cb53714","value":"Downloading: 100%"}},"d5063d7094764d49ab0db7b304dfc312":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_713f4f578b71461791f17fc31e8960ea","max":467042463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d1f4c8cd4bd5498fafa0951dd6f1b279","value":467042463}},"c12c278119bb48c3975bad0db3995e06":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8b1790a8cc1246febe1b02be7e35e115","placeholder":"​","style":"IPY_MODEL_65c48d1c432f468ba766d133fb1131fc","value":" 445M/445M [00:18&lt;00:00, 19.3MB/s]"}},"e7cf09a88641432b8fa3f3a05784270b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1ec49031dc8a4272b083ebe1849e63a0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c04680ce084648b2bade574e3cb53714":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"713f4f578b71461791f17fc31e8960ea":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d1f4c8cd4bd5498fafa0951dd6f1b279":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8b1790a8cc1246febe1b02be7e35e115":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"65c48d1c432f468ba766d133fb1131fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}