{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31301,"status":"ok","timestamp":1656634705988,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"},"user_tz":180},"id":"GLxgv9OSFqYi","outputId":"e21d526d-1afa-4f8d-ba67-95f0af7f5cfa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","\n","import os\n","os.chdir('/content/drive/My Drive/Colab Notebooks/refine-epitope-deep-learning')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15656,"status":"ok","timestamp":1656634721636,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"},"user_tz":180},"id":"Eu47NwKQudlO","outputId":"c52cc427-d18d-4545-f977-e9122a82d589"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 9.4 MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n","  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n","\u001b[K     |████████████████████████████████| 6.6 MB 47.3 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n","\u001b[K     |████████████████████████████████| 596 kB 68.3 MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n","Collecting huggingface-hub<1.0,>=0.1.0\n","  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n","\u001b[K     |████████████████████████████████| 101 kB 14.3 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.20.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting optuna\n","  Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n","\u001b[K     |████████████████████████████████| 308 kB 7.4 MB/s \n","\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (6.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n","Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.1)\n","Collecting cliff\n","  Downloading cliff-3.10.1-py3-none-any.whl (81 kB)\n","\u001b[K     |████████████████████████████████| 81 kB 9.9 MB/s \n","\u001b[?25hCollecting cmaes>=0.8.2\n","  Downloading cmaes-0.8.2-py3-none-any.whl (15 kB)\n","Collecting alembic\n","  Downloading alembic-1.8.0-py3-none-any.whl (209 kB)\n","\u001b[K     |████████████████████████████████| 209 kB 68.5 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n","Collecting colorlog\n","  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n","Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.37)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n","Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.11.4)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.7.1)\n","Collecting Mako\n","  Downloading Mako-1.2.1-py3-none-any.whl (78 kB)\n","\u001b[K     |████████████████████████████████| 78 kB 7.8 MB/s \n","\u001b[?25hRequirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n","Collecting cmd2>=1.0.0\n","  Downloading cmd2-2.4.1-py3-none-any.whl (146 kB)\n","\u001b[K     |████████████████████████████████| 146 kB 76.3 MB/s \n","\u001b[?25hCollecting stevedore>=2.0.1\n","  Downloading stevedore-3.5.0-py3-none-any.whl (49 kB)\n","\u001b[K     |████████████████████████████████| 49 kB 7.0 MB/s \n","\u001b[?25hCollecting autopage>=0.4.0\n","  Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n","Collecting pbr!=2.1.0,>=2.0.0\n","  Downloading pbr-5.9.0-py2.py3-none-any.whl (112 kB)\n","\u001b[K     |████████████████████████████████| 112 kB 75.2 MB/s \n","\u001b[?25hCollecting pyperclip>=1.6\n","  Downloading pyperclip-1.8.2.tar.gz (20 kB)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n","Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n","Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (21.4.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.0)\n","Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n","Building wheels for collected packages: pyperclip\n","  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11137 sha256=b408f2a2bcc029e20ba6c0552e0d51296e133ac4bb8677da2ddacca5bbedd47e\n","  Stored in directory: /root/.cache/pip/wheels/9f/18/84/8f69f8b08169c7bae2dde6bd7daf0c19fca8c8e500ee620a28\n","Successfully built pyperclip\n","Installing collected packages: pyperclip, pbr, stevedore, Mako, cmd2, autopage, colorlog, cmaes, cliff, alembic, optuna\n","Successfully installed Mako-1.2.1 alembic-1.8.0 autopage-0.5.1 cliff-3.10.1 cmaes-0.8.2 cmd2-2.4.1 colorlog-6.6.0 optuna-2.10.1 pbr-5.9.0 pyperclip-1.8.2 stevedore-3.5.0\n"]}],"source":["!pip install transformers\n","!pip install optuna"]},{"cell_type":"markdown","metadata":{"id":"QEpSHqtISuKr"},"source":["# Preprocess data "]},{"cell_type":"code","execution_count":3,"metadata":{"id":"eNWYJ8r-c_w3","executionInfo":{"status":"ok","timestamp":1656634728016,"user_tz":180,"elapsed":6398,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n","import torch\n","from transformers import TrainingArguments, Trainer\n","from transformers import BertTokenizer, BertForSequenceClassification, BertModel\n","from transformers import EarlyStoppingCallback"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"aj8NS4koSdbh","executionInfo":{"status":"ok","timestamp":1656634728016,"user_tz":180,"elapsed":8,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["# Create torch dataset\n","class Dataset(torch.utils.data.Dataset):\n","    def __init__(self, encodings, labels=None):\n","        self.encodings = encodings\n","        self.labels = labels\n","\n","    def __getitem__(self, idx):\n","        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n","        if self.labels:\n","            item[\"labels\"] = torch.tensor(self.labels[idx])\n","        return item\n","\n","    def __len__(self):\n","        return len(self.encodings[\"input_ids\"])"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"3WcVTolFqPS9","executionInfo":{"status":"ok","timestamp":1656634732479,"user_tz":180,"elapsed":3,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}}},"outputs":[],"source":["def preprocess_data(data):\n","\n","    # Preprocess data\n","    X = list(data[\"sequence\"])\n","    y = list(data[\"label\"])\n","    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n","    X_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\n","    X_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)\n","\n","    train_dataset = Dataset(X_train_tokenized, y_train)\n","    val_dataset = Dataset(X_val_tokenized, y_val)\n","    return train_dataset, val_dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["13e0c20f9e2c42f7bb4ab170501bcb90","bddfb2804028498484c86399e817b9a0","8facfe72f88a438392d8e52a9e72425b","3db465e506854734a23c564145e11eab","53f9636a6641441b87bf2a09fcaa74cf","cba3e33b1e504206be9fb2a71f3b78b2","fe2db7046ce942b79923b0aef08a9b62","bda0d7d7e2e84275ad6068924e2bd48b","3d6232d3f59641efb711f6d9cb9c7696","e58c531f068747fe826a1ea50e82b9b9","79c48fb46c4a4b1bb22622cd14424fe8","1c157755825d457fb29a986205a119ed","c924e7bf0f234e6e99195c62be45a7d3","6065470a4e2241f58783f6d41adeabe9","cc1b904ac0af463f87dd9ae772c9e539","35b4e9483dc7463da8386438e882d212","bcf8170a7178413ab8b602f54c3146ad","fc831cde4b5149798e75558404cc19c9","d915857dbe9c4e4abdb8e3ca527923f4","1adff5ffa43e4ef08bc2c360265fd49d","b8050401f4e746f69c5a0db422ce4fd3","77788700ad0e40e6a30d009e61a2c213","5f6e411b202841e8bc6d35c6e1555de9","3a1b01b45faf4d1bb54e1fecb8b8893c","6d87eed42210483992bbe3f51bf59ba9","052219bbb7fa4d8881be72280811cf8c","6a9b8d1a74104510a839b4ae837c2e3e","51c173f83f8f4ac999c04d9abbdc225e","524f3834e05b4801bf0a282ec1352644","34267405fc964031bbcac4f0d623b568","56f95c5eb4484a7fa1e74bf9c7fc8446","dadae0b983864b428ac9f90d6432c010","0e40572f4dd047a3828a27fc6d84489c","3e7df2a9fc394044b2a54d40fe89635f","f76371e87c8c4941a5aff67980167c39","fc388a7ef8754dc5b7d1ab786997acfd","6255e967ddeb4ac0b418604801001fd1","fb22a74ed54d400f83cfc4cb2f6c2bb5","c28a85d43c7a4e1fa54ab6d0cf9278a6","0c83507d05d74338b4dc4dc5e5406e21","89c1cac3617642b7b442de2fe15aa0f6","bed74135ed6f4ed3b255db7e7e7e7596","72b06250b79b408d991c931fcef1f632","6cc121764a1e4e098e67a4c8d6e61812","78a02861b93f4a7b9e0231be242bf85f","548f1188072e40a4b2b02d6f799811fc","fa4518882e4741b08e929df2e293a7a9","212cff39b8034867bbb373d2bd7d3152","1ff86afadbad461088756ef8534ca141","df8eab425fa6461485c0f1eee77bfd67","295ee36456e14434ab1cdff6ad3b96c9","ca576c75ba144986b9baa55fa37f3007","ff108f5519b04890a17cc124956d4e73","e67ef7aff5a1475fb433c423c9d32e4a","d8030ed52fc6469a92eecea83c3f3f54"]},"executionInfo":{"elapsed":548217,"status":"ok","timestamp":1655860729881,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"},"user_tz":180},"id":"61S6rdO_FPMP","outputId":"4be3ca9c-9646-484b-93b5-ed1be3a18a3a"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/81.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13e0c20f9e2c42f7bb4ab170501bcb90"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c157755825d457fb29a986205a119ed"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/86.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f6e411b202841e8bc6d35c6e1555de9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/361 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e7df2a9fc394044b2a54d40fe89635f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading:   0%|          | 0.00/1.57G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78a02861b93f4a7b9e0231be242bf85f"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at Rostlab/prot_bert_bfd were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at Rostlab/prot_bert_bfd and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","\u001b[32m[I 2022-06-22 01:10:48,810]\u001b[0m A new study created in memory with name: no-name-14704b49-035e-4e41-8d84-1d8da66d1737\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 132\n","  Num Epochs = 2\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 66\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='66' max='66' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [66/66 01:56, Epoch 2/2]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.649606</td>\n","      <td>0.666667</td>\n","      <td>0.666667</td>\n","      <td>0.166667</td>\n","      <td>0.266667</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.602515</td>\n","      <td>0.727273</td>\n","      <td>0.600000</td>\n","      <td>0.750000</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-33\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-33/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-33/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-33/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-33/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from Rostlab/prot_bert_bfd-finetuned-classification/run-0/checkpoint-66 (score: 0.6666666666666665).\n","\u001b[32m[I 2022-06-22 01:12:47,008]\u001b[0m Trial 0 finished with value: 2.7439393939393937 and parameters: {'learning_rate': 2.1992910087298307e-05, 'num_train_epochs': 2, 'seed': 32, 'per_device_train_batch_size': 64}. Best is trial 0 with value: 2.7439393939393937.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 132\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 33\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='33' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [33/33 01:05, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.601423</td>\n","      <td>0.727273</td>\n","      <td>0.600000</td>\n","      <td>0.750000</td>\n","      <td>0.666667</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from Rostlab/prot_bert_bfd-finetuned-classification/run-1/checkpoint-33 (score: 0.6666666666666665).\n","\u001b[32m[I 2022-06-22 01:13:53,527]\u001b[0m Trial 1 finished with value: 2.7439393939393937 and parameters: {'learning_rate': 1.5059233155046064e-06, 'num_train_epochs': 1, 'seed': 5, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 2.7439393939393937.\u001b[0m\n","Trial:\n","***** Running training *****\n","  Num examples = 132\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 165\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='165' max='165' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [165/165 04:51, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.563004</td>\n","      <td>0.757576</td>\n","      <td>0.642857</td>\n","      <td>0.750000</td>\n","      <td>0.692308</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.497265</td>\n","      <td>0.787879</td>\n","      <td>0.727273</td>\n","      <td>0.666667</td>\n","      <td>0.695652</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.487600</td>\n","      <td>0.818182</td>\n","      <td>0.800000</td>\n","      <td>0.666667</td>\n","      <td>0.727273</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.458207</td>\n","      <td>0.848485</td>\n","      <td>0.888889</td>\n","      <td>0.666667</td>\n","      <td>0.761905</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.456902</td>\n","      <td>0.848485</td>\n","      <td>0.888889</td>\n","      <td>0.666667</td>\n","      <td>0.761905</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-33\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-33/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-33/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-33/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-33/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-66\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-66/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-66/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-66/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-66/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-99\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-99/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-99/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-99/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-99/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 33\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-165\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-165/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-165/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-165/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-165/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from Rostlab/prot_bert_bfd-finetuned-classification/run-2/checkpoint-132 (score: 0.761904761904762).\n","\u001b[32m[I 2022-06-22 01:18:46,486]\u001b[0m Trial 2 finished with value: 3.165945165945166 and parameters: {'learning_rate': 4.151621215437127e-06, 'num_train_epochs': 5, 'seed': 13, 'per_device_train_batch_size': 64}. Best is trial 2 with value: 3.165945165945166.\u001b[0m\n"]}],"source":["df_train = pd.read_csv(\"./input/data_train.csv\")\n","\n","sequence_formatted = []\n","for seq in df_train['sequence'].values:\n","  sequence_formatted.append(\" \".join(seq))\n","\n","data = pd.DataFrame({'sequence':sequence_formatted, 'label':df_train['label'].tolist()})\n","\n","#data = df_train\n","\n","data_op = data[:int(len(data)/5)]\n","\n","\n","# Define pretrained tokenizer and model\n","batch_size=4\n","model_name = \"Rostlab/prot_bert_bfd\"\n","tokenizer = BertTokenizer.from_pretrained(model_name)\n","model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n","\n","\n","\n","train_dataset_op, val_dataset_op = preprocess_data(data_op)\n","train_dataset, val_dataset = preprocess_data(data)\n","\n","# ----- 2. Fine-tune pretrained model -----#\n","# Define Trainer parameters\n","def compute_metrics(p):\n","    \n","    pred, labels = p\n","    pred = np.argmax(pred, axis=1)\n","\n","    accuracy = accuracy_score(y_true=labels, y_pred=pred)\n","    recall = recall_score(y_true=labels, y_pred=pred)\n","    precision = precision_score(y_true=labels, y_pred=pred)\n","    f1 = f1_score(y_true=labels, y_pred=pred)\n","\n","    return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}\n","\n","# Define Trainer\n","args = TrainingArguments(\n","    f\"{model_name}-finetuned-classification\",\n","    evaluation_strategy = \"epoch\",\n","    save_strategy = \"epoch\",\n","    learning_rate=2e-5,\n","    per_device_train_batch_size=batch_size,\n","    per_device_eval_batch_size=batch_size,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    load_best_model_at_end=True,\n","    metric_for_best_model='f1',\n","    optim=\"adamw_torch\"\n",")\n","\n","def model_init():\n","    return model\n","\n","trainer = Trainer(\n","    model_init=model_init,\n","    args=args,\n","    train_dataset=train_dataset_op,\n","    eval_dataset=val_dataset_op,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")\n","\n","\n","best_run = trainer.hyperparameter_search(n_trials=3, direction=\"maximize\")\n","\n"]},{"cell_type":"markdown","metadata":{"id":"CDK2oaTH4uLJ"},"source":["## Set the model with the best parameters and run it on the full dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"neG3sjnaUHP_","executionInfo":{"status":"ok","timestamp":1655861556875,"user_tz":180,"elapsed":827048,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"4305b8b4-0d77-4bcf-ef30-691eeee4e444"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running training *****\n","  Num examples = 660\n","  Num Epochs = 5\n","  Instantaneous batch size per device = 64\n","  Total train batch size (w. parallel, distributed & accumulation) = 64\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 825\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='825' max='825' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [825/825 13:48, Epoch 5/5]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Accuracy</th>\n","      <th>Precision</th>\n","      <th>Recall</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.386974</td>\n","      <td>0.855422</td>\n","      <td>0.870370</td>\n","      <td>0.734375</td>\n","      <td>0.796610</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.422713</td>\n","      <td>0.855422</td>\n","      <td>0.870370</td>\n","      <td>0.734375</td>\n","      <td>0.796610</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.391086</td>\n","      <td>0.879518</td>\n","      <td>0.892857</td>\n","      <td>0.781250</td>\n","      <td>0.833333</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>0.362900</td>\n","      <td>0.395698</td>\n","      <td>0.879518</td>\n","      <td>0.879310</td>\n","      <td>0.796875</td>\n","      <td>0.836066</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>0.362900</td>\n","      <td>0.400908</td>\n","      <td>0.879518</td>\n","      <td>0.892857</td>\n","      <td>0.781250</td>\n","      <td>0.833333</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["***** Running Evaluation *****\n","  Num examples = 166\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-165\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-165/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-165/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-165/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-165/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 166\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-330\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-330/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-330/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-330/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-330/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 166\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-495\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-495/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-495/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-495/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-495/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 166\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660/special_tokens_map.json\n","***** Running Evaluation *****\n","  Num examples = 166\n","  Batch size = 4\n","Saving model checkpoint to Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-825\n","Configuration saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-825/config.json\n","Model weights saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-825/pytorch_model.bin\n","tokenizer config file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-825/tokenizer_config.json\n","Special tokens file saved in Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-825/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from Rostlab/prot_bert_bfd-finetuned-classification/checkpoint-660 (score: 0.8360655737704917).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=825, training_loss=0.3157784016927083, metrics={'train_runtime': 829.4343, 'train_samples_per_second': 3.979, 'train_steps_per_second': 0.995, 'total_flos': 3278819860786800.0, 'train_loss': 0.3157784016927083, 'epoch': 5.0})"]},"metadata":{},"execution_count":7}],"source":["for n, v in best_run.hyperparameters.items():\n","    setattr(trainer.args, n, v)\n","\n","trainer.train_dataset=train_dataset\n","trainer.eval_dataset=val_dataset\n","\n","trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":87},"id":"Jvyc17u1IB2H","executionInfo":{"status":"ok","timestamp":1655861567722,"user_tz":180,"elapsed":10862,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"5830270f-8b19-4f90-c069-929474bdea98"},"outputs":[{"output_type":"stream","name":"stderr","text":["***** Running Prediction *****\n","  Num examples = 207\n","  Batch size = 4\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [52/52 00:09]\n","    </div>\n","    "]},"metadata":{}}],"source":["# ----- 3. Predict -----#\n","# Load test data\n","#test_data = pd.read_csv(\"test.csv\")\n","test = pd.read_csv(\"./input/data_test.csv\")\n","\n","sequence_formatted = []\n","for seq in test['sequence'].values:\n","  sequence_formatted.append(\" \".join(seq))\n","\n","test_data = pd.DataFrame({'sequence':sequence_formatted, 'label':test['label'].tolist()})\n","\n","\n","X_test = list(test_data[\"sequence\"])\n","X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n","\n","# Create torch dataset\n","test_dataset = Dataset(X_test_tokenized)\n","\n","# Make prediction\n","raw_pred, _, _ = trainer.predict(test_dataset)\n","\n","# Preprocess raw predictions\n","y_pred = np.argmax(raw_pred, axis=1)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ieo_rZQnMC1i","executionInfo":{"status":"ok","timestamp":1655861567722,"user_tz":180,"elapsed":33,"user":{"displayName":"Lindeberg Leite","userId":"13691959383703340166"}},"outputId":"b7591324-2339-49f1-aa5c-f5e0844e2cd5"},"outputs":[{"output_type":"stream","name":"stdout","text":["ROC_AUC: 0.8245798319327731\n","              precision    recall  f1-score   support\n","\n","           0       0.83      0.90      0.86       119\n","           1       0.85      0.75      0.80        88\n","\n","    accuracy                           0.84       207\n","   macro avg       0.84      0.82      0.83       207\n","weighted avg       0.84      0.84      0.83       207\n","\n"]}],"source":["from sklearn.metrics import accuracy_score, classification_report\n","from sklearn.metrics import roc_auc_score\n","\n","print(\"ROC_AUC:\", roc_auc_score(test_data['label'], y_pred))\n","\n","print(classification_report(test_data['label'], y_pred))"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"epitope_prediction_protbert_extentended.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"13e0c20f9e2c42f7bb4ab170501bcb90":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bddfb2804028498484c86399e817b9a0","IPY_MODEL_8facfe72f88a438392d8e52a9e72425b","IPY_MODEL_3db465e506854734a23c564145e11eab"],"layout":"IPY_MODEL_53f9636a6641441b87bf2a09fcaa74cf"}},"bddfb2804028498484c86399e817b9a0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cba3e33b1e504206be9fb2a71f3b78b2","placeholder":"​","style":"IPY_MODEL_fe2db7046ce942b79923b0aef08a9b62","value":"Downloading: 100%"}},"8facfe72f88a438392d8e52a9e72425b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bda0d7d7e2e84275ad6068924e2bd48b","max":81,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3d6232d3f59641efb711f6d9cb9c7696","value":81}},"3db465e506854734a23c564145e11eab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58c531f068747fe826a1ea50e82b9b9","placeholder":"​","style":"IPY_MODEL_79c48fb46c4a4b1bb22622cd14424fe8","value":" 81.0/81.0 [00:00&lt;00:00, 2.28kB/s]"}},"53f9636a6641441b87bf2a09fcaa74cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba3e33b1e504206be9fb2a71f3b78b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe2db7046ce942b79923b0aef08a9b62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bda0d7d7e2e84275ad6068924e2bd48b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3d6232d3f59641efb711f6d9cb9c7696":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e58c531f068747fe826a1ea50e82b9b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79c48fb46c4a4b1bb22622cd14424fe8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c157755825d457fb29a986205a119ed":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c924e7bf0f234e6e99195c62be45a7d3","IPY_MODEL_6065470a4e2241f58783f6d41adeabe9","IPY_MODEL_cc1b904ac0af463f87dd9ae772c9e539"],"layout":"IPY_MODEL_35b4e9483dc7463da8386438e882d212"}},"c924e7bf0f234e6e99195c62be45a7d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bcf8170a7178413ab8b602f54c3146ad","placeholder":"​","style":"IPY_MODEL_fc831cde4b5149798e75558404cc19c9","value":"Downloading: 100%"}},"6065470a4e2241f58783f6d41adeabe9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d915857dbe9c4e4abdb8e3ca527923f4","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1adff5ffa43e4ef08bc2c360265fd49d","value":112}},"cc1b904ac0af463f87dd9ae772c9e539":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b8050401f4e746f69c5a0db422ce4fd3","placeholder":"​","style":"IPY_MODEL_77788700ad0e40e6a30d009e61a2c213","value":" 112/112 [00:00&lt;00:00, 3.37kB/s]"}},"35b4e9483dc7463da8386438e882d212":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bcf8170a7178413ab8b602f54c3146ad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc831cde4b5149798e75558404cc19c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d915857dbe9c4e4abdb8e3ca527923f4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1adff5ffa43e4ef08bc2c360265fd49d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b8050401f4e746f69c5a0db422ce4fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"77788700ad0e40e6a30d009e61a2c213":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5f6e411b202841e8bc6d35c6e1555de9":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a1b01b45faf4d1bb54e1fecb8b8893c","IPY_MODEL_6d87eed42210483992bbe3f51bf59ba9","IPY_MODEL_052219bbb7fa4d8881be72280811cf8c"],"layout":"IPY_MODEL_6a9b8d1a74104510a839b4ae837c2e3e"}},"3a1b01b45faf4d1bb54e1fecb8b8893c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_51c173f83f8f4ac999c04d9abbdc225e","placeholder":"​","style":"IPY_MODEL_524f3834e05b4801bf0a282ec1352644","value":"Downloading: 100%"}},"6d87eed42210483992bbe3f51bf59ba9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34267405fc964031bbcac4f0d623b568","max":86,"min":0,"orientation":"horizontal","style":"IPY_MODEL_56f95c5eb4484a7fa1e74bf9c7fc8446","value":86}},"052219bbb7fa4d8881be72280811cf8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dadae0b983864b428ac9f90d6432c010","placeholder":"​","style":"IPY_MODEL_0e40572f4dd047a3828a27fc6d84489c","value":" 86.0/86.0 [00:00&lt;00:00, 2.40kB/s]"}},"6a9b8d1a74104510a839b4ae837c2e3e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51c173f83f8f4ac999c04d9abbdc225e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"524f3834e05b4801bf0a282ec1352644":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34267405fc964031bbcac4f0d623b568":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56f95c5eb4484a7fa1e74bf9c7fc8446":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dadae0b983864b428ac9f90d6432c010":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e40572f4dd047a3828a27fc6d84489c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3e7df2a9fc394044b2a54d40fe89635f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f76371e87c8c4941a5aff67980167c39","IPY_MODEL_fc388a7ef8754dc5b7d1ab786997acfd","IPY_MODEL_6255e967ddeb4ac0b418604801001fd1"],"layout":"IPY_MODEL_fb22a74ed54d400f83cfc4cb2f6c2bb5"}},"f76371e87c8c4941a5aff67980167c39":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c28a85d43c7a4e1fa54ab6d0cf9278a6","placeholder":"​","style":"IPY_MODEL_0c83507d05d74338b4dc4dc5e5406e21","value":"Downloading: 100%"}},"fc388a7ef8754dc5b7d1ab786997acfd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_89c1cac3617642b7b442de2fe15aa0f6","max":361,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bed74135ed6f4ed3b255db7e7e7e7596","value":361}},"6255e967ddeb4ac0b418604801001fd1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72b06250b79b408d991c931fcef1f632","placeholder":"​","style":"IPY_MODEL_6cc121764a1e4e098e67a4c8d6e61812","value":" 361/361 [00:00&lt;00:00, 10.5kB/s]"}},"fb22a74ed54d400f83cfc4cb2f6c2bb5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c28a85d43c7a4e1fa54ab6d0cf9278a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0c83507d05d74338b4dc4dc5e5406e21":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89c1cac3617642b7b442de2fe15aa0f6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bed74135ed6f4ed3b255db7e7e7e7596":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72b06250b79b408d991c931fcef1f632":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cc121764a1e4e098e67a4c8d6e61812":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"78a02861b93f4a7b9e0231be242bf85f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_548f1188072e40a4b2b02d6f799811fc","IPY_MODEL_fa4518882e4741b08e929df2e293a7a9","IPY_MODEL_212cff39b8034867bbb373d2bd7d3152"],"layout":"IPY_MODEL_1ff86afadbad461088756ef8534ca141"}},"548f1188072e40a4b2b02d6f799811fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_df8eab425fa6461485c0f1eee77bfd67","placeholder":"​","style":"IPY_MODEL_295ee36456e14434ab1cdff6ad3b96c9","value":"Downloading: 100%"}},"fa4518882e4741b08e929df2e293a7a9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca576c75ba144986b9baa55fa37f3007","max":1684058277,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ff108f5519b04890a17cc124956d4e73","value":1684058277}},"212cff39b8034867bbb373d2bd7d3152":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e67ef7aff5a1475fb433c423c9d32e4a","placeholder":"​","style":"IPY_MODEL_d8030ed52fc6469a92eecea83c3f3f54","value":" 1.57G/1.57G [00:40&lt;00:00, 61.6MB/s]"}},"1ff86afadbad461088756ef8534ca141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df8eab425fa6461485c0f1eee77bfd67":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"295ee36456e14434ab1cdff6ad3b96c9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca576c75ba144986b9baa55fa37f3007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ff108f5519b04890a17cc124956d4e73":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e67ef7aff5a1475fb433c423c9d32e4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8030ed52fc6469a92eecea83c3f3f54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}